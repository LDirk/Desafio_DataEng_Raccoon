from pyspark.sql import SparkSession
import pandas as pd

spark = SparkSession \
    .builder \
    .appName("Python Spark SQL basic example") \
    .config("spark.some.config.option", "some-value") \
    .getOrCreate()
    
url_psel_de_shows = "https://us-central1-raccoon-bi.cloudfunctions.net/psel_de_shows"

url_psel_de_ingressos = "https://us-central1-raccoon-bi.cloudfunctions.net/psel_de_ingressos"

url_psel_de_compras = "https://us-central1-raccoon-bi.cloudfunctions.net/psel_de_compras"
 
df_psel_de_shows_0 = pd.read_json(url_psel_de_shows)
df_psel_de_shows = spark.createDataFrame(df_psel_de_shows_0)
#df_psel_de_shows

df_psel_de_ingressos_0 = pd.read_json(url_psel_de_ingressos)
df_psel_de_ingressos = spark.createDataFrame(df_psel_de_ingressos_0)
#df_psel_de_ingressos

df_psel_de_compras_0 = pd.read_csv(url_psel_de_compras)
df_psel_de_compras = spark.createDataFrame(df_psel_de_compras_0)
#df_psel_de_compras

df_psel_de_shows.createOrReplaceTempView("psel_de_show")
df_psel_de_ingressos.createOrReplaceTempView("psel_de_ingressos")
df_psel_de_compras.createOrReplaceTempView("psel_de_compras")

df1 = spark.sql("SELECT * FROM psel_de_show").show()
df2 = spark.sql("SELECT * FROM psel_de_ingressos").show()
df3 = spark.sql("SELECT * FROM psel_de_compras").show()


# 1. Qual a m√©dia de gastos de pessoas com ingresso Pista?

df_0 = spark.sql( "SELECT *, Case when dia=1 then 'Terrestrial Chair' when dia=2 then 'Nascent Letter' when dia=3 then 'Symbolic Toy' END AS show FROM psel_de_ingressos where tipo ='Pista'and status='Concluido' ")
df_0.createOrReplaceTempView("q1")
#df_0.show()

df_x = spark.sql(""" select * from psel_de_compras where nome  = 'Donna Wal'  """)

df_1 = spark.sql( " select nome as nome2, show as show2, gastos from  psel_de_compras ")
df_1.createOrReplaceTempView("q2")


df_2 = spark.sql(""" 
SELECT q1.*, q2.*
 
from q1 as q1 
left join q2 as q2
on 
q1.nome =q2.nome2 and q1.show=q2.show2 

""" )

df_2.createOrReplaceTempView("q3")

df_3 = spark.sql( " select ano,dia,mes,nome,status,tipo,show,sum(gastos) as gastos from  q3 where gastos is not null  group by 1,2,3,4,5,6,7").show()

#df_3.createOrReplaceTempView("q4")

#df_4 = spark.sql( " select AVG(gastos) as MEDIA_DOS_GASTOS from  q4 ").show()
# 3875
